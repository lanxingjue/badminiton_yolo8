"""
æ¨¡å‹è®­ç»ƒå™¨ - è®­ç»ƒç¾½æ¯›çƒåŠ¨ä½œåˆ†ç±»æ¨¡å‹
LinusåŸåˆ™ï¼šå·¥å…·è¦ç®€å•ã€å¯é ã€å¯é¢„æµ‹
é›†æˆäº†æˆåŠŸçš„äººä½“é€‰æ‹©ç®—æ³• + GPUä¼˜åŒ–æ”¯æŒ + ç¨³å®šæ€§å¢å¼º
"""

import os
import glob
import cv2
import torch
import torch.cuda.amp as amp  # ğŸ”§ æ··åˆç²¾åº¦è®­ç»ƒ
import numpy as np
from torch.utils.data import Dataset, DataLoader
from typing import List, Tuple, Optional
import random
import time
import json
from datetime import datetime
from ultralytics import YOLO

from detector import BadmintonDetector
from core import Keypoints
from config import MODEL_CONFIG, TRAINING_CONFIG, RAW_CLASSES

def get_optimal_config():
    """
    æ ¹æ®ç¡¬ä»¶è‡ªåŠ¨ä¼˜åŒ–é…ç½®
    é’ˆå¯¹RTX 4090ç­‰é«˜ç«¯GPUè¿›è¡Œä¼˜åŒ–
    """
    if torch.cuda.is_available():
        device = torch.device('cuda')
        gpu_name = torch.cuda.get_device_name(0)
        vram_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3
        
        print(f"ğŸš€ æ£€æµ‹åˆ°GPU: {gpu_name}")
        print(f"ğŸ’¾ æ˜¾å­˜: {vram_gb:.1f}GB")
        
        # RTX 4090ä¼˜åŒ–é…ç½® - ä¿®å¤é…ç½®å†²çª
        if "4090" in gpu_name or "4080" in gpu_name:
            batch_size = 128
            num_workers = 0  # ğŸ”§ é¿å…CUDAå¤šè¿›ç¨‹é—®é¢˜
            prefetch_factor = None  # ğŸ”§ å•è¿›ç¨‹æ¨¡å¼å¿…é¡»ä¸ºNone
            print("ğŸ¯ ä½¿ç”¨RTX 4090ä¼˜åŒ–é…ç½®ï¼ˆå•è¿›ç¨‹æ¨¡å¼ï¼‰")
        elif "3090" in gpu_name or "3080" in gpu_name:
            batch_size = 96
            num_workers = 0  # ğŸ”§ ç»Ÿä¸€ä½¿ç”¨å•è¿›ç¨‹
            prefetch_factor = None
            print("ğŸ¯ ä½¿ç”¨RTX 30ç³»ä¼˜åŒ–é…ç½®ï¼ˆå•è¿›ç¨‹æ¨¡å¼ï¼‰")
        elif "2080" in gpu_name or "2070" in gpu_name:
            batch_size = 64
            num_workers = 0  # ğŸ”§ ç»Ÿä¸€ä½¿ç”¨å•è¿›ç¨‹
            prefetch_factor = None
            print("ğŸ¯ ä½¿ç”¨RTX 20ç³»ä¼˜åŒ–é…ç½®ï¼ˆå•è¿›ç¨‹æ¨¡å¼ï¼‰")
        else:
            batch_size = 32
            num_workers = 0  # ğŸ”§ ç»Ÿä¸€ä½¿ç”¨å•è¿›ç¨‹
            prefetch_factor = None
            print("ğŸ¯ ä½¿ç”¨é€šç”¨GPUé…ç½®ï¼ˆå•è¿›ç¨‹æ¨¡å¼ï¼‰")
            
        return {
            'device': device,
            'batch_size': batch_size,
            'num_workers': num_workers,
            'prefetch_factor': prefetch_factor,  # ğŸ”§ å…³é”®ä¿®å¤
            'pin_memory': True,
            'mixed_precision': False,
            'persistent_workers': False
        }
    else:
        print("âš ï¸ æœªæ£€æµ‹åˆ°GPUï¼Œä½¿ç”¨CPUé…ç½®")
        return {
            'device': torch.device('cpu'),
            'batch_size': 16,
            'num_workers': 0,
            'prefetch_factor': None,  # ğŸ”§ å…³é”®ä¿®å¤
            'pin_memory': False,
            'mixed_precision': False,
            'persistent_workers': False
        }


def preprocess_frame_stable(frame):
    """
    ğŸ”§ ç¨³å®šç‰ˆå›¾åƒé¢„å¤„ç†
    æé«˜å›¾åƒè´¨é‡ï¼Œå¢å¼ºäººä½“æ£€æµ‹æ•ˆæœ
    """
    try:
        # æé«˜å¯¹æ¯”åº¦å’Œäº®åº¦
        frame = cv2.convertScaleAbs(frame, alpha=1.2, beta=10)
        # é”åŒ–æ»¤æ³¢å»é™¤è¿åŠ¨æ¨¡ç³Š
        kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
        frame = cv2.filter2D(frame, -1, kernel)
        return frame
    except Exception as e:
        print(f"    âš ï¸ é¢„å¤„ç†å¤±è´¥: {e}, è¿”å›åŸå›¾")
        return frame

def safe_float_robust(value):
    """
    ğŸ”§ ç»ˆæç‰ˆæ•°å€¼è½¬æ¢å‡½æ•°
    """
    try:
        if value is None:
            return 0.0
        
        if isinstance(value, (int, float)):
            if np.isnan(value) or np.isinf(value):
                return 0.0
            return float(value)
        
        if hasattr(value, 'dtype'):
            arr = np.asarray(value)
            
            if arr.size == 0:
                return 0.0
            
            if arr.ndim == 0:
                val = float(arr.item())
                return 0.0 if (np.isnan(val) or np.isinf(val)) else val
            
            # å¯¹äºå¤šå…ƒç´ æ•°ç»„ï¼Œå–ç¬¬ä¸€ä¸ªæœ‰æ•ˆå€¼
            flat = arr.flatten()
            for i in range(len(flat)):
                val = float(flat[i])
                if not (np.isnan(val) or np.isinf(val)):
                    return val
            
            return 0.0
        
        val = float(value)
        return 0.0 if (np.isnan(val) or np.isinf(val)) else val
        
    except Exception:
        return 0.0

def select_nearest_person_keypoints_stable(results, frame_height=640, frame_width=640):
    """
    ğŸ”§ Linuså¼è°ƒè¯•ç‰ˆï¼šäººä½“é€‰æ‹©ç®—æ³•
    """
    # print(f"    ğŸ” ã€äººä½“é€‰æ‹©å¼€å§‹ã€‘")
    
    try:
        # # æ£€æŸ¥1: resultsæœ‰æ•ˆæ€§
        # print(f"      æ£€æŸ¥1 - Results:")
        # print(f"        ç±»å‹: {type(results)}")
        # print(f"        æ˜¯å¦ä¸ºNone: {results is None}")
        # print(f"        é•¿åº¦: {len(results) if results else 'N/A'}")
        
        if not results or len(results) == 0:
            # print(f"      âŒ æ£€æŸ¥1å¤±è´¥: resultsæ— æ•ˆ")
            return None, None

        # æ£€æŸ¥2: ç¬¬ä¸€ä¸ªç»“æœ
        result = results[0]
        # print(f"      æ£€æŸ¥2 - ç¬¬ä¸€ä¸ªç»“æœ:")
        # print(f"        ç±»å‹: {type(result)}")
        # print(f"        æ˜¯å¦æœ‰keypointså±æ€§: {hasattr(result, 'keypoints')}")
        
        if not hasattr(result, 'keypoints') or result.keypoints is None:
            # print(f"      âŒ æ£€æŸ¥2å¤±è´¥: æ— keypointså±æ€§æˆ–ä¸ºNone")
            return None, None

        # æ£€æŸ¥3: keypointsæ•°æ®
        keypoints_data = result.keypoints
        # print(f"      æ£€æŸ¥3 - Keypointsæ•°æ®:")
        # print(f"        ç±»å‹: {type(keypoints_data)}")
        # print(f"        æ˜¯å¦æœ‰xyå±æ€§: {hasattr(keypoints_data, 'xy')}")
        # print(f"        æ˜¯å¦æœ‰confå±æ€§: {hasattr(keypoints_data, 'conf')}")
        
        if not hasattr(keypoints_data, 'xy'):
            # print(f"      âŒ æ£€æŸ¥3å¤±è´¥: æ— xyå±æ€§")
            return None, None
            
        # print(f"        xyé•¿åº¦: {len(keypoints_data.xy)}")
        
        if len(keypoints_data.xy) == 0:
            # print(f"      âŒ æ£€æŸ¥3å¤±è´¥: xyä¸ºç©º")
            return None, None

        # å¼€å§‹å¤„ç†æ¯ä¸ªäºº
        # print(f"      ğŸ¯ å¼€å§‹å¤„ç† {len(keypoints_data.xy)} ä¸ªäººç‰©")
        
        best_idx = None
        max_score = 0.0
        max_possible_area = float(frame_height * frame_width)
        valid_persons = 0

        for i in range(len(keypoints_data.xy)):
            # print(f"        ğŸ‘¤ äººç‰©{i+1}:")
            
            try:
                # æ•°æ®è·å–
                coords_tensor = keypoints_data.xy[i]
                confidence_tensor = keypoints_data.conf[i]
                
                # print(f"          æ•°æ®ç±»å‹: coords={type(coords_tensor)}, conf={type(confidence_tensor)}")
                # print(f"          æ•°æ®å½¢çŠ¶: coords={coords_tensor.shape}, conf={confidence_tensor.shape}")
                
                # è½¬æ¢ä¸ºnumpy
                coords = coords_tensor.cpu().numpy().astype(np.float32)
                confidence = confidence_tensor.cpu().numpy().astype(np.float32)
                
                # print(f"          numpyå½¢çŠ¶: coords={coords.shape}, conf={confidence.shape}")
                # print(f"          ç½®ä¿¡åº¦ç»Ÿè®¡: min={confidence.min():.3f}, max={confidence.max():.3f}, mean={confidence.mean():.3f}")
                
                if coords.size == 0 or confidence.size == 0:
                    # print(f"          âŒ æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡")
                    continue

                # è¿‡æ»¤æœ‰æ•ˆå…³é”®ç‚¹
                valid_mask = confidence > 0.05  # ä½¿ç”¨è¾ƒä½é˜ˆå€¼
                valid_points = coords[valid_mask]
                valid_conf = confidence[valid_mask]
                
                # print(f"          æœ‰æ•ˆå…³é”®ç‚¹: {len(valid_points)}/17 (é˜ˆå€¼>0.05)")
                
                if len(valid_points) < 1:  # è‡³å°‘éœ€è¦1ä¸ªå…³é”®ç‚¹
                    # print(f"          âŒ æœ‰æ•ˆå…³é”®ç‚¹ä¸è¶³ï¼Œè·³è¿‡")
                    continue

                # è®¡ç®—åŒ…å›´ç›’
                x_coords = valid_points[:, 0]
                y_coords = valid_points[:, 1]
                
                x_min, x_max = float(np.min(x_coords)), float(np.max(x_coords))
                y_min, y_max = float(np.min(y_coords)), float(np.max(y_coords))
                
                bbox_width = max(0.0, x_max - x_min)
                bbox_height = max(0.0, y_max - y_min)
                bbox_area = max(1.0, bbox_width * bbox_height)
                
                # print(f"          åŒ…å›´ç›’: å®½{bbox_width:.1f}, é«˜{bbox_height:.1f}, é¢ç§¯{bbox_area:.1f}")
                
                # è®¡ç®—è´¨å¿ƒ
                centroid_y = float(np.mean(y_coords))
                position_score = max(0.0, min(1.0, centroid_y / frame_height))
                
                # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
                avg_confidence = float(np.mean(valid_conf))
                
                # print(f"          è´¨å¿ƒY: {centroid_y:.1f}, ä½ç½®è¯„åˆ†: {position_score:.3f}")
                # print(f"          å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
                
                # ç®€åŒ–è¯„åˆ†ç®—æ³•
                composite_score = avg_confidence * 0.7 + position_score * 0.3
                
                # print(f"          ğŸ’¯ ç»¼åˆè¯„åˆ†: {composite_score:.3f}")
                
                valid_persons += 1
                
                if composite_score > max_score:
                    max_score = composite_score
                    best_idx = i
                    # print(f"          ğŸ‘‘ æ–°çš„æœ€ä½³å€™é€‰!")
                    
            except Exception as person_e:
                # print(f"          âŒ å¤„ç†äººç‰©{i+1}å¼‚å¸¸: {person_e}")
                import traceback
                traceback.print_exc()
                continue

        # print(f"      ğŸ“Š å¤„ç†å®Œæˆ: æœ‰æ•ˆäººç‰©{valid_persons}ä¸ª, æœ€ä½³ç´¢å¼•{best_idx}, æœ€é«˜åˆ†{max_score:.3f}")

        if best_idx is None:
            # print(f"      âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆå€™é€‰")
            return None, None

        # è¿”å›ç»“æœ
        try:
            best_keypoints = keypoints_data.xy[best_idx].cpu().numpy()
            best_confidence = keypoints_data.conf[best_idx].cpu().numpy()
            
            # print(f"      âœ… æˆåŠŸè¿”å›: äººç‰©{best_idx+1}")
            # print(f"        å…³é”®ç‚¹shape: {best_keypoints.shape}")
            # print(f"        ç½®ä¿¡åº¦shape: {best_confidence.shape}")
            
            return best_keypoints, best_confidence
            
        except Exception as return_e:
            # print(f"      âŒ è¿”å›ç»“æœå¼‚å¸¸: {return_e}")
            import traceback
            traceback.print_exc()
            return None, None
            
    except Exception as main_e:
        # print(f"    âŒ ä¸»å‡½æ•°å¼‚å¸¸: {main_e}")
        import traceback
        traceback.print_exc()
        return None, None

class VideoBadmintonDataset(Dataset):
    """
    VideoBadmintonæ•°æ®é›†åŠ è½½å™¨
    é›†æˆäº†ç¨³å®šçš„äººä½“æ£€æµ‹é€»è¾‘ + GPUä¼˜åŒ–
    """
    
    def __init__(self, dataset_dir: str, max_samples_per_class: Optional[int] = None, use_gpu: bool = True):
        """
        åˆå§‹åŒ–æ•°æ®é›†
        
        Args:
            dataset_dir: æ•°æ®é›†ç›®å½• (å¦‚ data/split/train/)
            max_samples_per_class: æ¯ä¸ªç±»åˆ«æœ€å¤§æ ·æœ¬æ•°ï¼Œç”¨äºé™åˆ¶æ•°æ®é‡
            use_gpu: æ˜¯å¦ä½¿ç”¨GPUä¼˜åŒ–æ¨¡å‹
        """
        self.dataset_dir = dataset_dir
        self.max_samples_per_class = max_samples_per_class
        self.samples = self._collect_samples()
        
        print(f"ğŸ“ æ•°æ®é›†ç›®å½•: {dataset_dir}")
        print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {len(self.samples)}")
        self._print_class_distribution()
        
        # ğŸ”§ GPUä¼˜åŒ–ï¼šæ ¹æ®ç¡¬ä»¶é€‰æ‹©æ›´åˆé€‚çš„YOLOv8æ¨¡å‹
        if use_gpu and torch.cuda.is_available():
            # GPUæ¨¡å¼ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹ï¼Œæ£€æµ‹ç²¾åº¦æ›´é«˜
            self.pose_model = YOLO('yolov8m-pose.pt')
            print("ğŸ¯ GPUæ¨¡å¼ï¼šä½¿ç”¨YOLOv8m-poseæ¨¡å‹")
        else:
            # CPUæ¨¡å¼ä½¿ç”¨è½»é‡çº§æ¨¡å‹
            self.pose_model = YOLO('yolov8n-pose.pt')
            print("ğŸ¯ CPUæ¨¡å¼ï¼šä½¿ç”¨YOLOv8n-poseæ¨¡å‹")
    
    def _collect_samples(self) -> List[Tuple[str, int]]:
        """æ”¶é›†æ‰€æœ‰è§†é¢‘æ–‡ä»¶å’Œå¯¹åº”æ ‡ç­¾"""
        samples = []
        
        # éå†18ä¸ªåŠ¨ä½œç±»åˆ«æ–‡ä»¶å¤¹
        for class_id in range(18):
            # æŸ¥æ‰¾å¯¹åº”çš„ç±»åˆ«æ–‡ä»¶å¤¹
            class_folders = glob.glob(os.path.join(self.dataset_dir, f"{class_id:02d}_*"))
            
            if not class_folders:
                continue
            
            class_folder = class_folders[0]  # åº”è¯¥åªæœ‰ä¸€ä¸ªåŒ¹é…çš„æ–‡ä»¶å¤¹
            video_files = glob.glob(os.path.join(class_folder, "*.mp4"))
            
            # é™åˆ¶æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°é‡ï¼ˆå¦‚æœæŒ‡å®šäº†ï¼‰
            if self.max_samples_per_class and len(video_files) > self.max_samples_per_class:
                video_files = random.sample(video_files, self.max_samples_per_class)
            
            # æ·»åŠ åˆ°æ ·æœ¬åˆ—è¡¨
            for video_file in video_files:
                samples.append((video_file, class_id))
        
        # éšæœºæ‰“ä¹±æ ·æœ¬é¡ºåº
        random.shuffle(samples)
        return samples
    
    def _print_class_distribution(self):
        """æ‰“å°ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡"""
        class_counts = {}
        for _, label in self.samples:
            class_counts[label] = class_counts.get(label, 0) + 1
        
        print("\nğŸ“ˆ ç±»åˆ«åˆ†å¸ƒ:")
        for class_id in sorted(class_counts.keys()):
            class_name = RAW_CLASSES.get(class_id, f"Class_{class_id}")
            print(f"  {class_id:02d} - {class_name}: {class_counts[class_id]} ä¸ªæ ·æœ¬")
    
    def __len__(self) -> int:
        return len(self.samples)
    
    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:
        """
        è·å–ä¸€ä¸ªè®­ç»ƒæ ·æœ¬
        
        Returns:
            (å…³é”®ç‚¹åºåˆ—å¼ é‡, åŠ¨ä½œç±»åˆ«æ ‡ç­¾)
        """
        video_path, label = self.samples[idx]
        
        # ä»è§†é¢‘ä¸­æå–å…³é”®ç‚¹åºåˆ—
        keypoints_sequence = self._extract_keypoints_from_video(video_path)
        
        if not keypoints_sequence:
            # å¦‚æœæå–å¤±è´¥ï¼Œè¿”å›é›¶å¼ é‡
            zero_tensor = torch.zeros(MODEL_CONFIG['keypoints'] * 2 * MODEL_CONFIG['sequence_length'])
            return zero_tensor, label
        
        # è½¬æ¢ä¸ºå›ºå®šé•¿åº¦çš„å¼ é‡
        sequence_tensor = self._keypoints_to_tensor(keypoints_sequence)
        return sequence_tensor, label
    
    def _extract_keypoints_from_video(self, video_path: str) -> List[Keypoints]:
        """
        ğŸ”§ Linuså¼è°ƒè¯•ç‰ˆï¼šä»è§†é¢‘æå–å…³é”®ç‚¹åºåˆ—
        æ¯ä¸ªæ­¥éª¤éƒ½æœ‰è¯¦ç»†æ—¥å¿—ï¼Œå®šä½é—®é¢˜
        """
        video_name = os.path.basename(video_path)
        # print(f"\nğŸ¬ å¼€å§‹å¤„ç†è§†é¢‘: {video_name}")
        # print(f"ğŸ“ å®Œæ•´è·¯å¾„: {video_path}")
        
        # æ­¥éª¤1: è§†é¢‘åŠ è½½
        cap = cv2.VideoCapture(video_path)
        keypoints_list = []
        
        if not cap.isOpened():
            print(f"âŒ è§†é¢‘æ‰“å¼€å¤±è´¥: {video_path}")
            return []
        
        # è·å–è§†é¢‘åŸºæœ¬ä¿¡æ¯
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        # print(f"ğŸ“Š è§†é¢‘ä¿¡æ¯: {width}x{height}, {total_frames}å¸§, {fps:.1f}fps")   
        
        frame_count = 0
        max_frames = TRAINING_CONFIG['max_frames_per_video']
        successful_detections = 0
        
        # print(f"ğŸ¯ å°†å¤„ç†æœ€å¤š {max_frames} å¸§")
        
        while frame_count < max_frames:
            ret, frame = cap.read()
            if not ret:
                # print(f"ğŸ“¹ ç¬¬{frame_count+1}å¸§è¯»å–å¤±è´¥ï¼Œè§†é¢‘ç»“æŸ")
                break
            
            # print(f"\nğŸ” å¤„ç†ç¬¬{frame_count+1}å¸§:")
            # print(f"  åŸå§‹å¸§å°ºå¯¸: {frame.shape}")
            
            try:
                # æ­¥éª¤2: å›¾åƒè£å‰ª
                height, width = frame.shape[:2]
                crop_y1 = max(0, int(height * 0.02))
                crop_y2 = min(height, int(height * 0.98))
                crop_x1 = max(0, int(width * 0.02))
                crop_x2 = min(width, int(width * 0.98))
                
                # print(f"  è£å‰ªåŒºåŸŸ: y[{crop_y1}:{crop_y2}], x[{crop_x1}:{crop_x2}]")
                
                cropped_frame = frame[crop_y1:crop_y2, crop_x1:crop_x2]
                # print(f"  è£å‰ªåå°ºå¯¸: {cropped_frame.shape}")
                
                # æ­¥éª¤3: å›¾åƒé¢„å¤„ç†
                try:
                    processed_frame = preprocess_frame_stable(cropped_frame)
                    # print(f"  é¢„å¤„ç†å®Œæˆ: {processed_frame.shape}")
                except Exception as preprocess_e:
                    # print(f"  âš ï¸ é¢„å¤„ç†å¤±è´¥: {preprocess_e}")
                    processed_frame = cropped_frame
                
                # æ­¥éª¤4: å°ºå¯¸è°ƒæ•´
                target_size = 640
                frame_resized = cv2.resize(processed_frame, (target_size, target_size))
                # print(f"  è°ƒæ•´åˆ°ç›®æ ‡å°ºå¯¸: {frame_resized.shape}")
                
                # æ­¥éª¤5: YOLOæ£€æµ‹ - å…³é”®ç¯èŠ‚
                # print(f"  ğŸ¤– å¼€å§‹YOLOæ£€æµ‹...")
                # print(f"  YOLOæ¨¡å‹ç±»å‹: {type(self.pose_model)}")
                
                try:
                    results = self.pose_model(frame_resized, verbose=False, conf=0.03)
                    # print(f"  âœ… YOLOæ£€æµ‹å®Œæˆ")
                    # print(f"  Resultsç±»å‹: {type(results)}")
                    # print(f"  Resultsé•¿åº¦: {len(results) if results else 'None'}")
                    
                    if results and len(results) > 0:
                        result = results[0]
                        # print(f"  ç¬¬ä¸€ä¸ªresultç±»å‹: {type(result)}")
                        # print(f"  resultå±æ€§: {[attr for attr in dir(result) if not attr.startswith('_')]}")
                        # print(f"  æ˜¯å¦æœ‰keypoints: {hasattr(result, 'keypoints')}")
                        
                        if hasattr(result, 'keypoints') and result.keypoints is not None:
                            kp_data = result.keypoints
                            # print(f"  keypointsç±»å‹: {type(kp_data)}")
                            # print(f"  keypointså±æ€§: {[attr for attr in dir(kp_data) if not attr.startswith('_')]}")
                            # print(f"  æ˜¯å¦æœ‰xy: {hasattr(kp_data, 'xy')}")
                            # print(f"  æ˜¯å¦æœ‰conf: {hasattr(kp_data, 'conf')}")
                            
                            # if hasattr(kp_data, 'xy'):
                            #     # print(f"  xyç±»å‹: {type(kp_data.xy)}")
                            #     # print(f"  æ£€æµ‹åˆ°äººæ•°: {len(kp_data.xy)}")
                                
                            #     if len(kp_data.xy) > 0:
                            #         # print(f"  ç¬¬ä¸€ä¸ªäººå…³é”®ç‚¹:")
                            #         # print(f"    xy shape: {kp_data.xy[0].shape}")
                            #         # print(f"    xyç±»å‹: {type(kp_data.xy)}")
                            #         # if hasattr(kp_data, 'conf'):
                            #             # print(f"    conf shape: {kp_data.conf.shape}")
                            #             # print(f"    confç±»å‹: {type(kp_data.conf)}")
                            #             # print(f"    ç½®ä¿¡åº¦èŒƒå›´: {kp_data.conf.min():.3f}-{kp_data.conf.max():.3f}")
                            #     else:
                            # #         print(f"  âŒ xyæ•°ç»„ä¸ºç©º")
                        #     # else:
                        #     #     print(f"  âŒ keypointsæ²¡æœ‰xyå±æ€§")
                        # else:
                        #     print(f"  âŒ resultæ²¡æœ‰keypointsæˆ–keypointsä¸ºNone")
                    else:
                        print(f"  âŒ YOLOè¿”å›ç©ºç»“æœ")
                    
                except Exception as yolo_e:
                    print(f"  âŒ YOLOæ£€æµ‹å¼‚å¸¸: {yolo_e}")
                    import traceback
                    traceback.print_exc()
                    frame_count += 1
                    continue
                
                # æ­¥éª¤6: äººä½“é€‰æ‹©
                # print(f"  ğŸ‘¤ å¼€å§‹äººä½“é€‰æ‹©...")
                try:
                    best_keypoints, best_confidence = select_nearest_person_keypoints_stable(
                        results, target_size, target_size
                    )
                    
                    if best_keypoints is not None and best_confidence is not None:
                        # print(f"  âœ… äººä½“é€‰æ‹©æˆåŠŸ")
                        # print(f"    å…³é”®ç‚¹shape: {best_keypoints.shape}")
                        # print(f"    ç½®ä¿¡åº¦shape: {best_confidence.shape}")
                        
                        # æ­¥éª¤7: è´¨é‡æ£€æŸ¥
                        try:
                            avg_confidence = safe_float_robust(best_confidence.mean())
                            # print(f"    å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
                            
                            if avg_confidence > 0.02:
                                # print(f"    âœ… è´¨é‡æ£€æŸ¥é€šè¿‡ï¼Œæ·»åŠ åˆ°åºåˆ—")
                                keypoints_list.append(Keypoints(
                                    points=best_keypoints,
                                    confidence=best_confidence
                                ))
                                successful_detections += 1
                            # else:
                                # print(f"    âŒ è´¨é‡æ£€æŸ¥å¤±è´¥ï¼Œå¹³å‡ç½®ä¿¡åº¦{avg_confidence:.3f} <= 0.02")
                        except Exception as quality_e:
                            print(f"    âŒ è´¨é‡æ£€æŸ¥å¼‚å¸¸: {quality_e}")
                    # else:
                        # print(f"  âŒ äººä½“é€‰æ‹©å¤±è´¥ï¼Œè¿”å›None")
                        
                except Exception as select_e:
                    # print(f"  âŒ äººä½“é€‰æ‹©å¼‚å¸¸: {select_e}")
                    import traceback
                    traceback.print_exc()
            
            except Exception as frame_e:
                print(f"  âŒ å¤„ç†ç¬¬{frame_count+1}å¸§å¼‚å¸¸: {frame_e}")
                import traceback
                traceback.print_exc()
            
            frame_count += 1
            
            # æ—©åœæ£€æŸ¥
            if frame_count > 30 and successful_detections == 0:
                print(f"ğŸ›‘ æ—©åœï¼šå¤„ç†äº†{frame_count}å¸§ï¼ŒæˆåŠŸ0æ¬¡")
                break
        
        cap.release()
        
        # æœ€ç»ˆç»Ÿè®¡
        success_rate = successful_detections / max(frame_count, 1) * 100
        # print(f"\nğŸ“Š è§†é¢‘å¤„ç†å®Œæˆ:")
        # print(f"  æ€»å¤„ç†å¸§æ•°: {frame_count}")
        # print(f"  æˆåŠŸæ£€æµ‹å¸§æ•°: {successful_detections}")
        # print(f"  æ£€æµ‹æˆåŠŸç‡: {success_rate:.1f}%")
        # print(f"  å…³é”®ç‚¹åºåˆ—é•¿åº¦: {len(keypoints_list)}")
        
        if success_rate < 5:
            print(f"âš ï¸  {video_name}: æ£€æµ‹æˆåŠŸç‡ {success_rate:.1f}% ({successful_detections}/{frame_count})")
        
        return keypoints_list
    
    def _keypoints_to_tensor(self, keypoints_sequence: List[Keypoints]) -> torch.Tensor:
        """
        å°†å…³é”®ç‚¹åºåˆ—è½¬æ¢ä¸ºå›ºå®šé•¿åº¦çš„å¼ é‡
        
        Args:
            keypoints_sequence: å…³é”®ç‚¹åºåˆ—
            
        Returns:
            å›ºå®šé•¿åº¦çš„å¼ é‡ (340ç»´: 17å…³é”®ç‚¹ Ã— 2åæ ‡ Ã— 10å¸§)
        """
        target_length = MODEL_CONFIG['sequence_length']
        
        if len(keypoints_sequence) >= target_length:
            # å¦‚æœåºåˆ—è¿‡é•¿ï¼Œå‡åŒ€é‡‡æ ·é€‰æ‹©ä»£è¡¨æ€§å¸§
            indices = np.linspace(0, len(keypoints_sequence) - 1, target_length, dtype=int)
            selected_keypoints = [keypoints_sequence[i] for i in indices]
        else:
            # å¦‚æœåºåˆ—è¿‡çŸ­ï¼Œé‡‡ç”¨é‡å¤å¡«å……ç­–ç•¥
            selected_keypoints = keypoints_sequence.copy()
            while len(selected_keypoints) < target_length:
                if keypoints_sequence:
                    # é‡å¤æœ€åä¸€å¸§
                    selected_keypoints.append(keypoints_sequence[-1])
                else:
                    # å¦‚æœæ²¡æœ‰æœ‰æ•ˆå…³é”®ç‚¹ï¼Œç”¨é›¶å¡«å……
                    zero_keypoints = Keypoints(
                        points=np.zeros((MODEL_CONFIG['keypoints'], 2)),
                        confidence=np.zeros(MODEL_CONFIG['keypoints'])
                    )
                    selected_keypoints.append(zero_keypoints)
        
        # ğŸ”„ è½¬æ¢ä¸ºå¼ é‡ï¼šå±•å¹³æ‰€æœ‰å…³é”®ç‚¹åæ ‡
        sequence_data = []
        for keypoints in selected_keypoints:
            sequence_data.extend(keypoints.points.flatten())
        
        return torch.FloatTensor(sequence_data)

class Trainer:
    """
    ç¾½æ¯›çƒåŠ¨ä½œåˆ†ç±»æ¨¡å‹è®­ç»ƒå™¨ - GPUä¼˜åŒ–+ç¨³å®šæ€§å¢å¼ºç‰ˆæœ¬
    """
    
    def __init__(self, data_root: str = "data/split/", force_cpu: bool = False):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            data_root: åˆ†å‰²åçš„æ•°æ®é›†æ ¹ç›®å½•
            force_cpu: å¼ºåˆ¶ä½¿ç”¨CPUæ¨¡å¼
        """
        self.data_root = data_root
        
        # ğŸ”§ GPUä¼˜åŒ–é…ç½®
        if force_cpu:
            self.config = {
                'device': torch.device('cpu'),
                'batch_size': 16,
                'num_workers': 2,
                'prefetch_factor': 2,
                'pin_memory': False,
                'mixed_precision': False,
                'persistent_workers': False
            }
            print("ğŸ”§ å¼ºåˆ¶ä½¿ç”¨CPUæ¨¡å¼")
        else:
            self.config = get_optimal_config()
        
        self.device = self.config['device']
        
        print("ğŸš€ åˆå§‹åŒ–ç¾½æ¯›çƒåŠ¨ä½œåˆ†ç±»è®­ç»ƒå™¨ (ç¨³å®šå¢å¼ºç‰ˆ)")
        print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {self.device}")
        print(f"ğŸ“ æ•°æ®æ ¹ç›®å½•: {data_root}")
        print(f"ğŸ¯ æ‰¹æ¬¡å¤§å°: {self.config['batch_size']}")
        print(f"ğŸ¯ å·¥ä½œçº¿ç¨‹: {self.config['num_workers']}")
        print(f"ğŸ¯ æ··åˆç²¾åº¦: {self.config['mixed_precision']}")
        print("ğŸ¯ é›†æˆäº†ç¨³å®šçš„äººä½“é€‰æ‹©ç®—æ³•")
        
        # ğŸ”§ æš‚æ—¶ç¦ç”¨æ··åˆç²¾åº¦è®­ç»ƒç¡®ä¿ç¨³å®šæ€§
        if self.config['mixed_precision']:
            try:
                self.scaler = amp.GradScaler()
                print("âš¡ å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒåŠ é€Ÿ")
            except:
                self.config['mixed_precision'] = False
                print("âš ï¸ æ··åˆç²¾åº¦åˆå§‹åŒ–å¤±è´¥ï¼Œç¦ç”¨æ··åˆç²¾åº¦")
        
        # éªŒè¯æ•°æ®ç›®å½•
        self._validate_data_directories()
    
    def _validate_data_directories(self):
        """éªŒè¯æ•°æ®ç›®å½•ç»“æ„"""
        required_dirs = ['train', 'val', 'test']
        for dir_name in required_dirs:
            dir_path = os.path.join(self.data_root, dir_name)
            if not os.path.exists(dir_path):
                raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°å¿…éœ€çš„ç›®å½•: {dir_path}")
        print("âœ… æ•°æ®ç›®å½•ç»“æ„éªŒè¯é€šè¿‡")
    
    def train(self, epochs: int = TRAINING_CONFIG['max_epochs'], 
              save_path: str = "badminton_model_stable.pth"):
        """
        è®­ç»ƒæ¨¡å‹ - GPUä¼˜åŒ–+ç¨³å®šæ€§å¢å¼ºç‰ˆæœ¬
        
        Args:
            epochs: è®­ç»ƒè½®æ•°
            save_path: æ¨¡å‹ä¿å­˜è·¯å¾„
        """
        print("=" * 60)
        print("ğŸ¸ å¼€å§‹è®­ç»ƒç¾½æ¯›çƒåŠ¨ä½œåˆ†ç±»æ¨¡å‹ (ç¨³å®šå¢å¼ºç‰ˆ)")
        print("=" * 60)
        
        training_start_time = time.time()
        
        # åŠ è½½æ•°æ®é›†
        print("ğŸ“‚ æ­£åœ¨åŠ è½½æ•°æ®é›†...")
        use_gpu_models = self.device.type == 'cuda'
        
        train_dataset = VideoBadmintonDataset(f"{self.data_root}/train/", use_gpu=use_gpu_models)
        val_dataset = VideoBadmintonDataset(f"{self.data_root}/val/", use_gpu=use_gpu_models)
        test_dataset = VideoBadmintonDataset(f"{self.data_root}/test/", use_gpu=use_gpu_models)
        
        print(f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆ")
        print(f"   è®­ç»ƒé›†: {len(train_dataset)} ä¸ªæ ·æœ¬")
        print(f"   éªŒè¯é›†: {len(val_dataset)} ä¸ªæ ·æœ¬")
        print(f"   æµ‹è¯•é›†: {len(test_dataset)} ä¸ªæ ·æœ¬")
        
        # ğŸ”§ GPUä¼˜åŒ–çš„æ•°æ®åŠ è½½å™¨
        train_loader = DataLoader(
            train_dataset,
            batch_size=self.config['batch_size'],
            shuffle=True,
            num_workers=self.config['num_workers'],
            pin_memory=self.config['pin_memory'],
            persistent_workers=self.config['persistent_workers'],
            prefetch_factor=self.config['prefetch_factor'],
            drop_last=True  # ç¡®ä¿æ‰¹æ¬¡å¤§å°ä¸€è‡´ï¼Œæœ‰åˆ©äºBatchNorm
        )
        
        val_loader = DataLoader(
            val_dataset,
            batch_size=self.config['batch_size'],
            shuffle=False,
            num_workers=self.config['num_workers'],
            pin_memory=self.config['pin_memory'],
            persistent_workers=self.config['persistent_workers'],
            prefetch_factor=self.config['prefetch_factor']
        )
        
        # åˆå§‹åŒ–æ¨¡å‹
        detector = BadmintonDetector()
        model = detector.action_classifier.to(self.device)
        
        # ğŸ”§ GPUä¼˜åŒ–ï¼šæ¨¡å‹ç¼–è¯‘ï¼ˆPyTorch 2.0+ï¼‰
        if torch.cuda.is_available() and hasattr(torch, 'compile'):
            try:
                model = torch.compile(model, mode='default')  # ä½¿ç”¨defaultæ¨¡å¼ç¡®ä¿ç¨³å®šæ€§
                print("âš¡ æ¨¡å‹ç¼–è¯‘ä¼˜åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âš ï¸ æ¨¡å‹ç¼–è¯‘å¤±è´¥ï¼Œä½¿ç”¨æ ‡å‡†æ¨¡å¼: {e}")
        
        # è®­ç»ƒé…ç½®
        criterion = torch.nn.CrossEntropyLoss()
        
        # ğŸ”§ GPUä¼˜åŒ–ï¼šä½¿ç”¨AdamWä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡scaling
        base_lr = MODEL_CONFIG['learning_rate']
        scaled_lr = base_lr * (self.config['batch_size'] / 16)  # æ ¹æ®æ‰¹æ¬¡å¤§å°è°ƒæ•´å­¦ä¹ ç‡
        
        optimizer = torch.optim.AdamW(
            model.parameters(),
            lr=scaled_lr,
            weight_decay=MODEL_CONFIG['weight_decay'],
            betas=(0.9, 0.999),
            eps=1e-8
        )
        
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            optimizer,
            mode='min',
            patience=TRAINING_CONFIG['lr_scheduler_patience'],
            factor=0.5
        )
        
        # è®­ç»ƒçŠ¶æ€è·Ÿè¸ª
        best_val_accuracy = 0.0
        epochs_without_improvement = 0
        training_history = {
            'train_loss': [],
            'train_acc': [],
            'val_loss': [],
            'val_acc': [],
            'learning_rate': []
        }
        
        print(f"ğŸ”§ ç¨³å®šå¢å¼ºè®­ç»ƒé…ç½®:")
        print(f"   æ‰¹æ¬¡å¤§å°: {self.config['batch_size']}")
        print(f"   åŸºç¡€å­¦ä¹ ç‡: {base_lr:.6f}")
        print(f"   ç¼©æ”¾å­¦ä¹ ç‡: {scaled_lr:.6f}")
        print(f"   æœ€å¤§è½®æ•°: {epochs}")
        print(f"   æ··åˆç²¾åº¦: {self.config['mixed_precision']}")
        print("-" * 40)
        
        # ä¸»è®­ç»ƒå¾ªç¯
        for epoch in range(epochs):
            epoch_start_time = time.time()
            
            print(f"\nğŸ“… Epoch {epoch+1}/{epochs}")
            print("-" * 30)
            
            # è®­ç»ƒé˜¶æ®µ
            if self.config['mixed_precision']:
                train_loss, train_acc = self._train_epoch_amp(model, train_loader, criterion, optimizer)
            else:
                train_loss, train_acc = self._train_epoch(model, train_loader, criterion, optimizer)
            
            # éªŒè¯é˜¶æ®µ
            val_loss, val_acc = self._validate_epoch(model, val_loader, criterion)
            
            # æ›´æ–°å­¦ä¹ ç‡è°ƒåº¦å™¨
            scheduler.step(val_loss)
            current_lr = optimizer.param_groups[0]['lr']
            
            # è®°å½•è®­ç»ƒå†å²
            training_history['train_loss'].append(train_loss)
            training_history['train_acc'].append(train_acc)
            training_history['val_loss'].append(val_loss)
            training_history['val_acc'].append(val_acc)
            training_history['learning_rate'].append(current_lr)
            
            # æ˜¾ç¤ºå½“å‰è½®ç»“æœ
            epoch_time = time.time() - epoch_start_time
            
            # ğŸ”§ GPUå†…å­˜ç›‘æ§
            if torch.cuda.is_available():
                gpu_memory_used = torch.cuda.max_memory_allocated() / 1024**3
                gpu_memory_cached = torch.cuda.max_memory_reserved() / 1024**3
                gpu_info = f"| GPUå†…å­˜: {gpu_memory_used:.1f}GB/{gpu_memory_cached:.1f}GB"
            else:
                gpu_info = ""
            
            print(f"ğŸ“Š è®­ç»ƒæŸå¤±: {train_loss:.4f} | è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.2f}%")
            print(f"ğŸ“Š éªŒè¯æŸå¤±: {val_loss:.4f} | éªŒè¯å‡†ç¡®ç‡: {val_acc:.2f}%")
            print(f"â±ï¸  è½®æ¬¡è€—æ—¶: {epoch_time:.1f}ç§’ {gpu_info} | å­¦ä¹ ç‡: {current_lr:.6f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_val_accuracy:
                best_val_accuracy = val_acc
                epochs_without_improvement = 0
                
                torch.save(model.state_dict(), save_path)
                print(f"ğŸ¯ æ–°çš„æœ€ä½³æ¨¡å‹ï¼éªŒè¯å‡†ç¡®ç‡: {val_acc:.2f}% (å·²ä¿å­˜)")
            else:
                epochs_without_improvement += 1
            
            # æ—©åœæ£€æŸ¥
            if epochs_without_improvement >= TRAINING_CONFIG['early_stopping_patience']:
                print(f"â¹ï¸  æ—©åœè§¦å‘ï¼{epochs_without_improvement} è½®æ— æ”¹è¿›")
                break
            
            # ğŸ”§ æ¸…ç†GPUç¼“å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        
        # è®­ç»ƒç»“æŸç»Ÿè®¡
        total_training_time = time.time() - training_start_time
        print("\n" + "=" * 60)
        print("ğŸ‰ è®­ç»ƒå®Œæˆï¼")
        print(f"â±ï¸  æ€»è®­ç»ƒæ—¶é—´: {total_training_time:.1f}ç§’")
        print(f"ğŸ† æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_accuracy:.2f}%")
        print(f"ğŸ“ æ¨¡å‹å·²ä¿å­˜è‡³: {save_path}")
        
        # ä¿å­˜è®­ç»ƒå†å²
        history_path = save_path.replace('.pth', '_history.json')
        with open(history_path, 'w') as f:
            json.dump(training_history, f, indent=2)
        print(f"ğŸ“Š è®­ç»ƒå†å²å·²ä¿å­˜è‡³: {history_path}")
        
        # æœ€ç»ˆæµ‹è¯•è¯„ä¼°
        if os.path.exists(save_path):
            self._final_evaluation(test_dataset, save_path)
    
    def _train_epoch_amp(self, model, train_loader, criterion, optimizer) -> Tuple[float, float]:
        """è®­ç»ƒä¸€ä¸ªepoch - æ··åˆç²¾åº¦ç‰ˆæœ¬"""
        model.train()
        total_loss = 0.0
        correct = 0
        total = 0
        
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(self.device, non_blocking=True), target.to(self.device, non_blocking=True)
            
            optimizer.zero_grad(set_to_none=True)  # æ›´é«˜æ•ˆçš„æ¢¯åº¦æ¸…é›¶
            
            # ğŸ”§ ä½¿ç”¨ä¼ ç»Ÿçš„æ··åˆç²¾åº¦APIç¡®ä¿å…¼å®¹æ€§
            try:
                with torch.cuda.amp.autocast():
                    output = model(data)
                    loss = criterion(output, target)
                
                self.scaler.scale(loss).backward()
                self.scaler.step(optimizer)
                self.scaler.update()
            except Exception as amp_e:
                # å¦‚æœæ··åˆç²¾åº¦å¤±è´¥ï¼Œå›é€€åˆ°æ ‡å‡†æ¨¡å¼
                print(f"âš ï¸ æ··åˆç²¾åº¦å¤±è´¥ï¼Œå›é€€åˆ°æ ‡å‡†æ¨¡å¼: {amp_e}")
                output = model(data)
                loss = criterion(output, target)
                loss.backward()
                optimizer.step()
            
            # ç»Ÿè®¡
            total_loss += loss.item()
            _, predicted = torch.max(output.data, 1)
            total += target.size(0)
            correct += (predicted == target).sum().item()
            
            # æ˜¾ç¤ºè¿›åº¦
            if batch_idx % 50 == 0:  # GPUè®­ç»ƒæ›´å¿«ï¼Œå‡å°‘è¾“å‡ºé¢‘ç‡
                current_acc = 100.0 * correct / total
                print(f"  ğŸ“¦ æ‰¹æ¬¡ {batch_idx}/{len(train_loader)} | "
                      f"æŸå¤±: {loss.item():.4f} | å‡†ç¡®ç‡: {current_acc:.2f}%")
        
        avg_loss = total_loss / len(train_loader)
        accuracy = 100.0 * correct / total
        return avg_loss, accuracy
    
    def _train_epoch(self, model, train_loader, criterion, optimizer) -> Tuple[float, float]:
        """è®­ç»ƒä¸€ä¸ªepoch - æ ‡å‡†ç‰ˆæœ¬"""
        model.train()
        total_loss = 0.0
        correct = 0
        total = 0
        
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(self.device, non_blocking=True), target.to(self.device, non_blocking=True)
            
            optimizer.zero_grad(set_to_none=True)
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            
            # ğŸ”§ æ¢¯åº¦è£å‰ªé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            # ç»Ÿè®¡
            total_loss += loss.item()
            _, predicted = torch.max(output.data, 1)
            total += target.size(0)
            correct += (predicted == target).sum().item()
            
            # æ˜¾ç¤ºè¿›åº¦
            if batch_idx % 50 == 0:
                current_acc = 100.0 * correct / total
                print(f"  ğŸ“¦ æ‰¹æ¬¡ {batch_idx}/{len(train_loader)} | "
                      f"æŸå¤±: {loss.item():.4f} | å‡†ç¡®ç‡: {current_acc:.2f}%")
        
        avg_loss = total_loss / len(train_loader)
        accuracy = 100.0 * correct / total
        return avg_loss, accuracy
    
    def _validate_epoch(self, model, val_loader, criterion) -> Tuple[float, float]:
        """éªŒè¯ä¸€ä¸ªepoch"""
        model.eval()
        total_loss = 0.0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for data, target in val_loader:
                data, target = data.to(self.device, non_blocking=True), target.to(self.device, non_blocking=True)
                
                # ğŸ”§ ç¨³å®šçš„éªŒè¯æ¨ç†
                try:
                    if self.config['mixed_precision']:
                        with torch.cuda.amp.autocast():
                            output = model(data)
                            loss = criterion(output, target)
                    else:
                        output = model(data)
                        loss = criterion(output, target)
                except Exception as val_e:
                    # éªŒè¯å¤±è´¥æ—¶ä½¿ç”¨æ ‡å‡†æ¨¡å¼
                    output = model(data)
                    loss = criterion(output, target)
                
                total_loss += loss.item()
                _, predicted = torch.max(output.data, 1)
                total += target.size(0)
                correct += (predicted == target).sum().item()
        
        avg_loss = total_loss / len(val_loader)
        accuracy = 100.0 * correct / total
        return avg_loss, accuracy
    
    def _final_evaluation(self, test_dataset, model_path):
        """æœ€ç»ˆæµ‹è¯•é›†è¯„ä¼°"""
        print("\n" + "=" * 60)
        print("ğŸ§ª æœ€ç»ˆè¯„ä¼° (ä½¿ç”¨æµ‹è¯•é›†)")
        print("=" * 60)
        
        test_loader = DataLoader(
            test_dataset,
            batch_size=self.config['batch_size'],
            shuffle=False,
            num_workers=self.config['num_workers'],
            pin_memory=self.config['pin_memory']
        )
        
        # åŠ è½½æœ€ä½³æ¨¡å‹
        detector = BadmintonDetector()
        model = detector.action_classifier.to(self.device)
        model.load_state_dict(torch.load(model_path, map_location=self.device))
        model.eval()
        
        # è¯„ä¼°
        correct = 0
        total = 0
        class_correct = [0] * 18
        class_total = [0] * 18
        
        with torch.no_grad():
            for data, target in test_loader:
                data, target = data.to(self.device, non_blocking=True), target.to(self.device, non_blocking=True)
                
                # ç¨³å®šçš„æµ‹è¯•æ¨ç†
                try:
                    if self.config['mixed_precision']:
                        with torch.cuda.amp.autocast():
                            output = model(data)
                    else:
                        output = model(data)
                except:
                    output = model(data)
                
                _, predicted = torch.max(output, 1)
                
                total += target.size(0)
                correct += (predicted == target).sum().item()
                
                # æŒ‰ç±»åˆ«ç»Ÿè®¡
                for i in range(target.size(0)):
                    label = target[i].item()
                    class_total[label] += 1
                    if predicted[i] == target[i]:
                        class_correct[label] += 1
        
        # è¾“å‡ºæ•´ä½“ç»“æœ
        overall_accuracy = 100.0 * correct / total
        print(f"ğŸ¯ æµ‹è¯•é›†æ•´ä½“å‡†ç¡®ç‡: {overall_accuracy:.2f}% ({correct}/{total})")
        
        # è¾“å‡ºå„ç±»åˆ«è¯¦ç»†ç»“æœ
        print("\nğŸ“Š å„ç±»åˆ«è¯¦ç»†ç»“æœ:")
        print("-" * 80)
        print(f"{'ç±»åˆ«ID':<6} {'åŠ¨ä½œåç§°':<20} {'å‡†ç¡®ç‡':<10} {'æ ·æœ¬æ•°':<10}")
        print("-" * 80)
        
        for i in range(18):
            if class_total[i] > 0:
                acc = 100.0 * class_correct[i] / class_total[i]
                class_name = RAW_CLASSES.get(i, f"Class_{i}")
                print(f"{i:02d}     {class_name:<20} {acc:>6.2f}%     {class_total[i]:>4d}")
        
        print("-" * 80)
        print("âœ… æœ€ç»ˆè¯„ä¼°å®Œæˆ")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="è®­ç»ƒç¾½æ¯›çƒåŠ¨ä½œåˆ†ç±»æ¨¡å‹ (ç¨³å®šå¢å¼ºç‰ˆ)")
    parser.add_argument("--data", default="data/split/", 
                       help="åˆ†å‰²åçš„æ•°æ®é›†æ ¹ç›®å½•")
    parser.add_argument("--epochs", type=int, default=TRAINING_CONFIG['max_epochs'], 
                       help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--output", default="badminton_model_stable.pth", 
                       help="æ¨¡å‹è¾“å‡ºè·¯å¾„")
    parser.add_argument("--batch-size", type=int, default=None, 
                       help="æ‰¹æ¬¡å¤§å°ï¼ˆç•™ç©ºè‡ªåŠ¨ä¼˜åŒ–ï¼‰")
    parser.add_argument("--lr", type=float, default=MODEL_CONFIG['learning_rate'], 
                       help="å­¦ä¹ ç‡")
    parser.add_argument("--cpu", action="store_true", 
                       help="å¼ºåˆ¶ä½¿ç”¨CPUæ¨¡å¼")
    
    args = parser.parse_args()
    
    # æ›´æ–°é…ç½®
    if args.batch_size:
        MODEL_CONFIG['batch_size'] = args.batch_size
    MODEL_CONFIG['learning_rate'] = args.lr
    
    # è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡ç°
    torch.manual_seed(42)
    np.random.seed(42)
    random.seed(42)
    
    # ğŸ”§ GPUä¼˜åŒ–è®¾ç½®
    if torch.cuda.is_available() and not args.cpu:
        torch.cuda.manual_seed(42)
        torch.cuda.manual_seed_all(42)
        torch.backends.cudnn.deterministic = False  # å…è®¸éç¡®å®šæ€§ä»¥æé«˜æ€§èƒ½
        torch.backends.cudnn.benchmark = True       # ä¼˜åŒ–å·ç§¯æ€§èƒ½
    
    # å¼€å§‹è®­ç»ƒ
    trainer = Trainer(args.data, force_cpu=args.cpu)
    trainer.train(epochs=args.epochs, save_path=args.output)

if __name__ == "__main__":
    main()
