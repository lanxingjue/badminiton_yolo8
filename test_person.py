import cv2
from ultralytics import YOLO
import numpy as np
import os

def preprocess_frame(frame):
    """æé«˜å›¾åƒè´¨é‡ï¼Œå¢å¼ºäººä½“æ£€æµ‹"""
    frame = cv2.convertScaleAbs(frame, alpha=1.2, beta=10)
    kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
    frame = cv2.filter2D(frame, -1, kernel)
    return frame

def safe_float(value):
    """
    å®‰å…¨çš„æ•°å€¼è½¬æ¢ï¼Œå¤„ç†æ‰€æœ‰numpyç±»å‹
    """
    if isinstance(value, (np.ndarray, np.generic)):
        if hasattr(value, 'item'):
            return float(value.item())
        elif len(value.shape) == 0:  # 0ç»´æ•°ç»„ï¼ˆæ ‡é‡ï¼‰
            return float(value)
        elif value.size == 1:  # åªæœ‰ä¸€ä¸ªå…ƒç´ 
            return float(value.flat[0])
        else:
            raise ValueError(f"Cannot convert array of size {value.size} to scalar")
    else:
        return float(value)

def select_nearest_person(results, frame_height=640, frame_width=640):
    """ä»YOLOv8å§¿æ€æ£€æµ‹ç»“æœä¸­é€‰æ‹©æœ€é è¿‘æ‘„åƒå¤´çš„äºº"""
    if not results or len(results) == 0:
        return None, None, 0
    
    result = results[0]
    
    if not hasattr(result, 'keypoints') or result.keypoints is None:
        return None, None, 0
    
    keypoints_data = result.keypoints
    
    if len(keypoints_data.xy) == 0:
        return None, None, 0
    
    best_idx = None
    max_score = 0.0
    person_scores = []
    
    max_possible_area = float(frame_height * frame_width)
    
    for i in range(len(keypoints_data.xy)):
        try:
            coords = keypoints_data.xy[i].cpu().numpy().astype(np.float64)
            confidence = keypoints_data.conf[i].cpu().numpy().astype(np.float64)
            
            valid_mask = confidence > 0.3
            valid_points = coords[valid_mask]
            valid_conf = confidence[valid_mask]
            
            if len(valid_points) < 5:
                person_scores.append((i, 0.0, "insufficient_keypoints"))
                continue
            
            min_xy = valid_points.min(axis=0)
            max_xy = valid_points.max(axis=0)
            
            bbox_width = safe_float(max_xy[0] - min_xy[0])
            bbox_height = safe_float(max_xy[1] - min_xy[1])
            bbox_area = bbox_width * bbox_height
            
            centroid_y = safe_float(valid_points[:, 1].mean())
            position_score = centroid_y / frame_height
            
            avg_confidence = safe_float(valid_conf.mean())
            
            # ç»¼åˆè¯„åˆ†
            area_weight = 0.5
            position_weight = 0.3
            confidence_weight = 0.2
            
            if bbox_area > 0:
                normalized_area = min(np.log10(bbox_area + 1) / np.log10(max_possible_area + 1), 1.0)
            else:
                normalized_area = 0.0
            
            normalized_position = min(position_score, 1.0)
            normalized_confidence = min(avg_confidence, 1.0)
            
            composite_score = (
                area_weight * normalized_area +
                position_weight * normalized_position +
                confidence_weight * normalized_confidence
            )
            
            person_scores.append((
                i, 
                composite_score, 
                f"area:{bbox_area:.0f}_pos:{centroid_y:.0f}_conf:{avg_confidence:.2f}"
            ))
            
            if composite_score > max_score:
                max_score = composite_score
                best_idx = i
                
        except Exception as e:
            print(f"  âš ï¸ å¤„ç†äººç‰©{i}æ—¶å‡ºé”™: {e}")
            person_scores.append((i, 0.0, f"error: {str(e)}"))
            continue
    
    # è°ƒè¯•è¾“å‡º
    print(f"  å€™é€‰äººè¯„åˆ†:")
    for idx, score, details in person_scores:
        marker = "ğŸ‘‘" if idx == best_idx else "  "
        print(f"  {marker} äººç‰©{idx}: å¾—åˆ†{score:.3f} ({details})")
    
    if best_idx is None:
        return None, None, 0.0
    
    best_keypoints = keypoints_data.xy[best_idx].cpu().numpy()
    best_confidence = keypoints_data.conf[best_idx].cpu().numpy()
    
    return best_keypoints, best_confidence, max_score

def extract_keypoints_and_draw(video_path, output_dir, model_path='yolov8n-pose.pt', max_frames=50):
    """ä»è§†é¢‘ä¸­æå–å…³é”®ç‚¹å¹¶ç»˜åˆ¶éª¨æ¶"""
    try:
        model = YOLO(model_path)
        cap = cv2.VideoCapture(video_path)
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    if not cap.isOpened():
        print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
        return
    
    os.makedirs(output_dir, exist_ok=True)
    
    # è·å–è§†é¢‘ä¿¡æ¯
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    print(f"ğŸ¬ å¤„ç†è§†é¢‘: {os.path.basename(video_path)}")
    print(f"ğŸ“Š è§†é¢‘ä¿¡æ¯: {width}x{height}, {total_frames}å¸§, {fps:.1f}fps")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ¯ æœ€å¤§å¤„ç†å¸§æ•°: {max_frames}")
    print("-" * 50)
    
    frame_idx = 0
    saved_idx = 0
    detection_stats = []
    
    # éª¨æ¶è¿æ¥å®šä¹‰
    skeleton_pairs = [
        (0, 1), (0, 2), (1, 3), (2, 4),        # å¤´éƒ¨
        (5, 6), (5, 11), (6, 12), (11, 12),    # èº¯å¹²
        (5, 7), (7, 9),                        # å·¦è‡‚
        (6, 8), (8, 10),                       # å³è‡‚
        (11, 13), (13, 15),                    # å·¦è…¿
        (12, 14), (14, 16)                     # å³è…¿
    ]
    
    while frame_idx < max_frames and frame_idx < total_frames:
        ret, frame = cap.read()
        if not ret:
            break
        
        print(f"\nğŸ” å¤„ç†å¸§ {frame_idx + 1}/{min(max_frames, total_frames)}")
        
        try:
            # æ™ºèƒ½è£å‰ª
            original_height, original_width = frame.shape[:2]
            crop_y1 = int(original_height * 0.15)
            crop_y2 = int(original_height * 0.90)
            crop_x1 = int(original_width * 0.10)
            crop_x2 = int(original_width * 0.90)
            cropped_frame = frame[crop_y1:crop_y2, crop_x1:crop_x2]
            
            # é¢„å¤„ç†
            processed_frame = preprocess_frame(cropped_frame)
            
            # è°ƒæ•´å°ºå¯¸
            target_size = 640
            frame_resized = cv2.resize(processed_frame, (target_size, target_size))
            
            # YOLOv8æ£€æµ‹
            results = model(frame_resized, verbose=False, conf=0.1)
            
            # é€‰æ‹©æœ€ä½³äººä½“
            best_keypoints, best_confidence, best_score = select_nearest_person(
                results, target_size, target_size
            )
            
            if best_keypoints is not None and best_confidence is not None:
                print(f"  âœ… æ£€æµ‹æˆåŠŸï¼Œæœ€ä½³å€™é€‰å¾—åˆ†: {best_score:.3f}")
                
                # åˆ›å»ºç»˜åˆ¶å›¾åƒ
                draw_img = frame_resized.copy()
                
                # ğŸ”§ å…³é”®ä¿®æ­£ï¼šå®‰å…¨å¤„ç†æ‰€æœ‰åæ ‡è½¬æ¢
                valid_keypoints = []
                valid_confidences = []
                
                # é¢„å¤„ç†å…³é”®ç‚¹ï¼Œç¡®ä¿éƒ½æ˜¯å¯ç”¨çš„æ ‡é‡
                for i in range(len(best_keypoints)):
                    try:
                        x = safe_float(best_keypoints[i][0])
                        y = safe_float(best_keypoints[i][1])
                        conf = safe_float(best_confidence[i])
                        
                        if conf > 0.3 and 0 <= x < target_size and 0 <= y < target_size:
                            valid_keypoints.append((i, x, y, conf))
                            valid_confidences.append(conf)
                    except Exception as e:
                        print(f"    âš ï¸ è·³è¿‡å…³é”®ç‚¹{i}: {e}")
                        continue
                
                # ç»˜åˆ¶å…³é”®ç‚¹
                for i, x, y, conf in valid_keypoints:
                    # æ ¹æ®ç½®ä¿¡åº¦è®¾ç½®é¢œè‰²
                    if conf > 0.7:
                        color = (0, 255, 0)    # ç»¿è‰²
                    elif conf > 0.5:
                        color = (0, 255, 255)  # é»„è‰²
                    else:
                        color = (0, 0, 255)    # çº¢è‰²
                    
                    cv2.circle(draw_img, (int(x), int(y)), 4, color, -1)
                    cv2.putText(draw_img, str(i), (int(x)-5, int(y)-5), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255,255,255), 1)
                
                # ç»˜åˆ¶éª¨æ¶
                kp_dict = {i: (x, y, conf) for i, x, y, conf in valid_keypoints}
                
                for (p1, p2) in skeleton_pairs:
                    if p1 in kp_dict and p2 in kp_dict:
                        x1, y1, conf1 = kp_dict[p1]
                        x2, y2, conf2 = kp_dict[p2]
                        
                        if conf1 > 0.3 and conf2 > 0.3:
                            cv2.line(draw_img, (int(x1), int(y1)), (int(x2), int(y2)), 
                                    (0, 0, 255), 2)
                
                # æ·»åŠ ä¿¡æ¯æ–‡æœ¬
                avg_conf = np.mean(valid_confidences) if valid_confidences else 0
                
                info_text = [
                    f"Frame: {frame_idx + 1}",
                    f"Score: {best_score:.3f}",
                    f"Avg Conf: {avg_conf:.2f}",
                    f"Valid Points: {len(valid_keypoints)}/17"
                ]
                
                for i, text in enumerate(info_text):
                    cv2.putText(draw_img, text, (10, 25 + i * 20), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                # ä¿å­˜å›¾ç‰‡
                output_filename = f"frame_{saved_idx:04d}_score_{best_score:.3f}.jpg"
                output_path = os.path.join(output_dir, output_filename)
                
                if cv2.imwrite(output_path, draw_img):
                    print(f"  ğŸ’¾ å·²ä¿å­˜: {output_filename}")
                    saved_idx += 1
                    
                    detection_stats.append({
                        'frame': frame_idx,
                        'score': float(best_score),
                        'confidence': float(avg_conf),
                        'valid_points': len(valid_keypoints)
                    })
                else:
                    print(f"  âŒ ä¿å­˜å¤±è´¥: {output_filename}")
            else:
                print(f"  âŒ æœªæ£€æµ‹åˆ°æœ‰æ•ˆäººä½“")
        
        except Exception as e:
            print(f"  âš ï¸ å¤„ç†å¸§ {frame_idx + 1} æ—¶å‡ºé”™: {e}")
        
        frame_idx += 1
    
    cap.release()
    
    # è¾“å‡ºç»Ÿè®¡
    print("\n" + "=" * 50)
    print("ğŸ‰ å¤„ç†å®Œæˆï¼")
    print(f"ğŸ“Š æ€»å¤„ç†å¸§æ•°: {frame_idx}")
    print(f"âœ… æˆåŠŸæ£€æµ‹å¸§æ•°: {saved_idx}")
    
    if frame_idx > 0:
        print(f"ğŸ“ˆ æ£€æµ‹æˆåŠŸç‡: {saved_idx/frame_idx*100:.1f}%")
    
    print(f"ğŸ“ è¾“å‡ºå›¾ç‰‡ä¿å­˜åˆ°: {output_dir}")
    
    if detection_stats:
        avg_score = sum(s['score'] for s in detection_stats) / len(detection_stats)
        avg_conf = sum(s['confidence'] for s in detection_stats) / len(detection_stats)
        avg_points = sum(s['valid_points'] for s in detection_stats) / len(detection_stats)
        
        print(f"ğŸ“Š å¹³å‡è¯„åˆ†: {avg_score:.3f}")
        print(f"ğŸ“Š å¹³å‡ç½®ä¿¡åº¦: {avg_conf:.3f}")
        print(f"ğŸ“Š å¹³å‡æœ‰æ•ˆå…³é”®ç‚¹: {avg_points:.1f}/17")

if __name__ == "__main__":
    test_video = "data/split/train/14_Smash/2022-08-30_19-10-16_dataset_set1_130_011066_011084_A_14.mp4"
    test_output = "debug_output"
    
    if os.path.exists(test_video):
        extract_keypoints_and_draw(test_video, test_output, max_frames=18)
    else:
        print("âŒ æµ‹è¯•è§†é¢‘ä¸å­˜åœ¨")
